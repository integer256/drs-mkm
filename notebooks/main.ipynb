{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "First we import the data from the csv file. We use the pandas library to read the csv file and store it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train values shape:  (260601, 39)\n",
      "Train labels shape:  (260601, 2)\n",
      "Test values shape:  (86868, 39)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import importer\n",
    "\n",
    "raw_train_values, raw_train_labels, raw_test_values = importer.import_data(directory=\"../Data\")\n",
    "\n",
    "# Print the shapes of the data\n",
    "print(\"Train values shape: \", raw_train_values.shape)\n",
    "print(\"Train labels shape: \", raw_train_labels.shape)\n",
    "print(\"Test values shape: \", raw_test_values.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "We clean the data by removing the rows categorical data. This is a fast implementation of the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (260601, 40)\n",
      "Test data shape:  (86868, 39)\n"
     ]
    }
   ],
   "source": [
    "import cleaner\n",
    "\n",
    "train_data, test_data = cleaner.clean(raw_train_values, raw_train_labels, raw_test_values)\n",
    "\n",
    "# Print the shapes of the new data\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (260601, 82)\n",
      "Test data shape:  (86868, 81)\n",
      "Train data columns:  Index(['building_id', 'geo_level_1_id_0', 'geo_level_1_id_1',\n",
      "       'geo_level_1_id_2', 'geo_level_1_id_3', 'geo_level_1_id_4',\n",
      "       'geo_level_2_id_0', 'geo_level_2_id_1', 'geo_level_2_id_2',\n",
      "       'geo_level_2_id_3', 'geo_level_2_id_4', 'geo_level_2_id_5',\n",
      "       'geo_level_2_id_6', 'geo_level_2_id_7', 'geo_level_2_id_8',\n",
      "       'geo_level_2_id_9', 'geo_level_2_id_10', 'geo_level_3_id_0',\n",
      "       'geo_level_3_id_1', 'geo_level_3_id_2', 'geo_level_3_id_3',\n",
      "       'geo_level_3_id_4', 'geo_level_3_id_5', 'geo_level_3_id_6',\n",
      "       'geo_level_3_id_7', 'geo_level_3_id_8', 'geo_level_3_id_9',\n",
      "       'geo_level_3_id_10', 'geo_level_3_id_11', 'geo_level_3_id_12',\n",
      "       'geo_level_3_id_13', 'count_floors_pre_eq', 'age', 'area_percentage',\n",
      "       'height_percentage', 'land_surface_condition_0',\n",
      "       'land_surface_condition_1', 'foundation_type_0', 'foundation_type_1',\n",
      "       'foundation_type_2', 'roof_type_0', 'roof_type_1',\n",
      "       'ground_floor_type_0', 'ground_floor_type_1', 'ground_floor_type_2',\n",
      "       'other_floor_type_0', 'other_floor_type_1', 'other_floor_type_2',\n",
      "       'position_0', 'position_1', 'position_2', 'plan_configuration_0',\n",
      "       'plan_configuration_1', 'plan_configuration_2', 'plan_configuration_3',\n",
      "       'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
      "       'has_superstructure_stone_flag',\n",
      "       'has_superstructure_cement_mortar_stone',\n",
      "       'has_superstructure_mud_mortar_brick',\n",
      "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
      "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
      "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
      "       'legal_ownership_status_0', 'legal_ownership_status_1',\n",
      "       'legal_ownership_status_2', 'count_families', 'has_secondary_use',\n",
      "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
      "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
      "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
      "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
      "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
      "       'damage_grade'],\n",
      "      dtype='object')\n",
      "Test data columns:  Index(['building_id', 'geo_level_1_id_0', 'geo_level_1_id_1',\n",
      "       'geo_level_1_id_2', 'geo_level_1_id_3', 'geo_level_1_id_4',\n",
      "       'geo_level_2_id_0', 'geo_level_2_id_1', 'geo_level_2_id_2',\n",
      "       'geo_level_2_id_3', 'geo_level_2_id_4', 'geo_level_2_id_5',\n",
      "       'geo_level_2_id_6', 'geo_level_2_id_7', 'geo_level_2_id_8',\n",
      "       'geo_level_2_id_9', 'geo_level_2_id_10', 'geo_level_3_id_0',\n",
      "       'geo_level_3_id_1', 'geo_level_3_id_2', 'geo_level_3_id_3',\n",
      "       'geo_level_3_id_4', 'geo_level_3_id_5', 'geo_level_3_id_6',\n",
      "       'geo_level_3_id_7', 'geo_level_3_id_8', 'geo_level_3_id_9',\n",
      "       'geo_level_3_id_10', 'geo_level_3_id_11', 'geo_level_3_id_12',\n",
      "       'geo_level_3_id_13', 'count_floors_pre_eq', 'age', 'area_percentage',\n",
      "       'height_percentage', 'land_surface_condition_0',\n",
      "       'land_surface_condition_1', 'foundation_type_0', 'foundation_type_1',\n",
      "       'foundation_type_2', 'roof_type_0', 'roof_type_1',\n",
      "       'ground_floor_type_0', 'ground_floor_type_1', 'ground_floor_type_2',\n",
      "       'other_floor_type_0', 'other_floor_type_1', 'other_floor_type_2',\n",
      "       'position_0', 'position_1', 'position_2', 'plan_configuration_0',\n",
      "       'plan_configuration_1', 'plan_configuration_2', 'plan_configuration_3',\n",
      "       'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
      "       'has_superstructure_stone_flag',\n",
      "       'has_superstructure_cement_mortar_stone',\n",
      "       'has_superstructure_mud_mortar_brick',\n",
      "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
      "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
      "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
      "       'legal_ownership_status_0', 'legal_ownership_status_1',\n",
      "       'legal_ownership_status_2', 'count_families', 'has_secondary_use',\n",
      "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
      "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
      "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
      "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
      "       'has_secondary_use_use_police', 'has_secondary_use_other'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import encoder\n",
    "\n",
    "train_data, test_data = encoder.encode(train_data, test_data)\n",
    "\n",
    "# Print the shapes of the new data\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)\n",
    "\n",
    "# Print the columns of the new data\n",
    "print(\"Train data columns: \", train_data.columns)\n",
    "print(\"Test data columns: \", test_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampler\n",
    "\n",
    "train_data = resampler.resample(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model\n",
    "\n",
    "We create a model using the sklearn library. We use the XGBoost to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "\n",
    "model = model.XGBoost(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluator\n",
    "\n",
    "predictions = evaluator.print_model_summary(model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a data frame with the predictions\n",
    "predictions = pd.DataFrame(predictions, columns=['damage_grade_0', 'damage_grade_1'])\n",
    "\n",
    "# Add the building_id column\n",
    "predictions['building_id'] = raw_test_values['building_id']\n",
    "\n",
    "# Rearrange the columns\n",
    "predictions = predictions[['building_id', 'damage_grade_0', 'damage_grade_1']]\n",
    "\n",
    "# Save the predictions in a csv file\n",
    "predictions.to_csv('../Data/predictions.csv', index=False)\n",
    "\n",
    "predictions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
